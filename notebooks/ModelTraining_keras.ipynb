{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936b2c4e-ddf7-4e02-88e3-e280af0f2621",
   "metadata": {},
   "source": [
    "# Training a simple CNN model in `keras` (>3.0) for Tornado Detection\n",
    "\n",
    "This notebook steps through how to train a simple CNN model using a subset of TorNet.\n",
    "\n",
    "This will not produce a model with any skill, but simply provides a working end-to-end example of how to set up a data loader, build, and fit a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441b4a7-07b3-42f9-b7b2-0925136c37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow' # set to 'tensorflow', 'torch' or 'jax' (installs required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392369dc-ade9-4d34-8a5f-9d7d7d24a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Uncomment if tornet isn't installed in your environment or in your path already\n",
    "#sys.path.append('../')  \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from tornet.data.tf.loader import create_tf_dataset \n",
    "from tornet.data.constants import ALL_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f31eb-e051-4d5f-880d-7ef0a8eddcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras accepts most data loaders (tensorflow, torch).\n",
    "# A pure keras data loader, with necessary preprocessing steps for the cnn baseline, is provided\n",
    "from tornet.data.keras.loader import KerasDataLoader\n",
    "data_root = os.environ['TORNET_ROOT']\n",
    "ds = KerasDataLoader(data_root=data_root,\n",
    "                     data_type='train',\n",
    "                     years=[2018,2019],\n",
    "                     batch_size = 8, \n",
    "                     workers = 4,\n",
    "                     use_multiprocessing = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d24ab7-0c41-4f14-864a-58d9831a2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple CNN model\n",
    "# This normalizes data, concatenates along channel, and applies a Conv2D\n",
    "from tornet.data.constants import CHANNEL_MIN_MAX\n",
    "from tornet.models.keras.layers import FillNaNs\n",
    "\n",
    "input_vars = ALL_VARIABLES # which variables to use\n",
    "\n",
    "# TF convention is B,L,W,H\n",
    "inputs = {v:keras.Input(shape=(120,240,2),name=v) for v in input_vars}\n",
    "\n",
    "# Normalize inputs\n",
    "norm_layers = []\n",
    "for v in input_vars:\n",
    "    min_max = np.array(CHANNEL_MIN_MAX[v]) # [2,]\n",
    "\n",
    "    # choose mean,var to get approximate [-1,1] scaling\n",
    "    var=((min_max[1]-min_max[0])/2)**2 # scalar\n",
    "    var=np.array(2*[var,])    # [n_sweeps,]\n",
    "    offset=(min_max[0]+min_max[1])/2    # scalar\n",
    "    offset=np.array(2*[offset,]) # [n_sweeps,]\n",
    "    \n",
    "    norm_layers.append(\n",
    "        keras.layers.Normalization(mean=offset, variance=var,\n",
    "                                   name='Normalized_%s' % v)\n",
    "    )\n",
    "\n",
    "# Concatenate normed inputs along channel dimension\n",
    "x=keras.layers.Concatenate(axis=-1,name='Concatenate1')(\n",
    "        [l(inputs[v]) for l,v in zip(norm_layers,input_vars)]\n",
    "        )\n",
    "\n",
    "# Replace background (nan) with -3\n",
    "x = FillNaNs(fill_val=-3,name='ReplaceNan')(x)\n",
    "\n",
    "# Processing\n",
    "x = keras.layers.Conv2D(32,3,padding='same',activation='relu')(x)\n",
    "# add more..\n",
    "x = keras.layers.Conv2D(1,1,padding='same',activation='relu',name='TornadoLikelihood')(x)\n",
    "y = keras.layers.GlobalMaxPool2D(name='GlobalMaxPool')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs,outputs=y,name='TornadoDetector')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfbfa0-3cdc-4676-864e-f7cbcd869443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "opt  = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss=keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f402213-58a7-44be-a1cb-4d0aa16428d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# steps_per_epoch=10 for demo purposes\n",
    "model.fit(ds,epochs=3,steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae798b07-9ac5-4784-ba44-cfa242649e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a test set\n",
    "ds_test = KerasDataLoader(data_root=data_root,\n",
    "                         data_type='test',\n",
    "                         years=[2018,2019],\n",
    "                         batch_size = 8, \n",
    "                         workers = 4,\n",
    "                         use_multiprocessing = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af44de5-af4e-438e-a0b1-153fbe72be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "import tornet.metrics.keras.metrics as km\n",
    "metrics = [keras.metrics.AUC(from_logits=True,name='AUC'),\n",
    "           km.BinaryAccuracy(from_logits=True,name='BinaryAccuracy'), \n",
    "           ]\n",
    "model.compile(loss=loss,metrics=metrics)\n",
    "\n",
    "# steps=10 for demo purposes\n",
    "model.evaluate(ds_test,steps=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
